{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNEm5Yk7cZRQ8nftDjEsfK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panditamey1/NLP_transformers/blob/main/transformers_pytorch_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self attention\n"
      ],
      "metadata": {
        "id": "vn8ulUZMZ0F4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key, Query, Value \n",
        "- Create matrices for KQV\n",
        " "
      ],
      "metadata": {
        "id": "qooexvOlvQCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "from torch import nn\n",
        "import torch\n",
        "torch.random.manual_seed(42)"
      ],
      "metadata": {
        "id": "yzTCG9iVwoZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4647f708-7511-41f7-c272-24685a787e4b"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3356a791b0>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 4\n",
        "d = 12 # model dimensions\n",
        "\n",
        "Wk = np.random.randn(d,d)\n",
        "Wq = np.random.randn(d,d)\n",
        "Wv = np.random.randn(d,d)\n",
        "\n",
        "Wk.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKduxupwvYgF",
        "outputId": "fb48649f-5913-4fcd-80bd-e95fe1dfa397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randn(t,d)  # t = token size"
      ],
      "metadata": {
        "id": "Ik2DzRnGxADa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-guacgexRny",
        "outputId": "5ad68669-fbb3-4768-fe2a-af2e30224490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- take dot product of (Q*K.T/np.sqrt(d) )* V"
      ],
      "metadata": {
        "id": "Hetf6QPgxc-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = np.dot(X, Wq)\n",
        "K = np.dot(X, Wk)\n",
        "\n",
        "K.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zku8qhhFxWF6",
        "outputId": "4fd16fe8-9f9b-44f9-df5d-ecfd0ab4d01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## dot product of q and k\n",
        "\n",
        "QK = np.dot(Q,K.T)\n"
      ],
      "metadata": {
        "id": "PR23S76xykgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QK = QK / np.sqrt(d)"
      ],
      "metadata": {
        "id": "ww-g18Fpyxex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Softmax\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    print(e_x.shape)\n",
        "    res =  e_x / e_x.sum(axis=0) # only difference\n",
        "    print(res.shape)\n",
        "    return res\n",
        "    "
      ],
      "metadata": {
        "id": "M1u6W0dIy4OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_QK = softmax(QK)\n",
        "QK.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ2S9x_94rnS",
        "outputId": "ad92233a-9b6d-4bdb-a422-3f945f601d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V = np.dot(X, Wv)"
      ],
      "metadata": {
        "id": "ku7BoWfc42iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvJUG_b65DRx",
        "outputId": "29f82565-ab9d-475d-eb7f-66ce652f8554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QKV = np.dot(scaled_QK, V)"
      ],
      "metadata": {
        "id": "Tkjy0r0C0CTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QKV.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LceO5GXk0N_v",
        "outputId": "45ec67d6-fd79-4d74-dfe5-e4f1b14eb1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jK2EEjkK5LcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create function for self attention"
      ],
      "metadata": {
        "id": "5BvXZ21m5kX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_self_attention(query, key, value):\n",
        "  key_dim = key.shape[1]\n",
        "  QK = np.dot(query,key.T)\n",
        "  #/np.sqrt(key_dim)\n",
        "  print(\"---\")\n",
        "  print(QK.shape)\n",
        "  #sf = nn.Softmax( dim=1)\n",
        "  scaled_QK = softmax(QK)\n",
        "  print(scaled_QK.shape)\n",
        "  QKV = np.dot(scaled_QK, value)\n",
        "  print(QKV.shape)\n",
        "  return QKV, scaled_QK"
      ],
      "metadata": {
        "id": "yzF3cQ4F5qhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_self_attention(Q, K, V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA4a3K2-62_p",
        "outputId": "0729ae5a-c71d-4413-c555-2f9d54048f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 6.59297357e-47,  6.11623018e-47,  2.09227010e-46,\n",
              "          1.90797248e-46, -1.28153513e-47, -1.09696246e-46,\n",
              "          2.74316935e-47, -6.58638251e-47, -1.39020227e-46,\n",
              "          2.01060110e-46,  7.13266126e-47, -1.89522458e-46],\n",
              "        [ 5.41346164e-40,  4.36153826e-40,  1.57390668e-39,\n",
              "          1.45347501e-39, -7.28558597e-41, -8.25978126e-40,\n",
              "          1.33804646e-40, -5.33975408e-40, -1.09072760e-39,\n",
              "          1.56123496e-39,  5.51334414e-40, -1.46958532e-39],\n",
              "        [-8.43764302e+00,  8.77144346e+00, -9.46910444e-01,\n",
              "          2.97250628e+00,  2.36695398e+00, -3.98113213e+00,\n",
              "         -2.28811882e+00,  4.45762186e+00,  4.50286565e+00,\n",
              "          1.52476604e+00,  2.72580162e+00, -3.35865925e-01],\n",
              "        [ 7.66125828e-32, -3.30838028e-32,  8.32463766e-32,\n",
              "          1.97255430e-32, -6.90215186e-32, -3.29037147e-31,\n",
              "         -6.06296034e-32,  1.18175743e-31,  1.12543985e-31,\n",
              "          4.17384358e-32,  1.40384174e-31, -3.48219463e-32]]),\n",
              " array([[9.02178750e-65, 3.96121058e-47, 5.14271272e-65, 9.66142092e-49],\n",
              "        [6.70014723e-63, 3.04006206e-40, 3.70511420e-48, 2.96643146e-54],\n",
              "        [1.32347586e-49, 6.87231950e-52, 1.00000000e+00, 3.95675085e-14],\n",
              "        [7.70681336e-32, 6.22393931e-53, 3.51300617e-43, 1.95615720e-71]]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi head attention"
      ],
      "metadata": {
        "id": "g2ar1x7v6_A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 3\n",
        "embed_dim = 4\n",
        "\n",
        "queries = np.random.rand(seq_len, embed_dim)\n",
        "keys = np.random.rand(seq_len, embed_dim)\n",
        "values = np.random.rand(seq_len, embed_dim)\n",
        "\n",
        "print(\"Queries:\\n\", queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CfIr4CFjXb3",
        "outputId": "6c3b995f-2512-4ac5-b843-e8d2815f7261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries:\n",
            " [[0.28484049 0.03688695 0.60956433 0.50267902]\n",
            " [0.05147875 0.27864646 0.90826589 0.23956189]\n",
            " [0.14489487 0.48945276 0.98565045 0.24205527]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, attn_weights = scaled_self_attention(queries, keys, values)\n",
        "\n",
        "print(\"Output\\n\", output, \"\\n\")\n",
        "print(\"Weights\\n\", attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9fmX9ksjhKf",
        "outputId": "c2e6c600-b144-4a9b-c746-3652065202a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n",
            "(3, 3)\n",
            "Output\n",
            " [[0.34046052 0.3583313  0.65012393 0.09111357]\n",
            " [0.40349096 0.37504672 0.71582375 0.1059299 ]\n",
            " [0.49985446 0.47074605 0.89351946 0.13143174]] \n",
            "\n",
            "Weights\n",
            " [[0.3254204  0.28426828 0.26285964]\n",
            " [0.29641855 0.31901007 0.33004653]\n",
            " [0.37816105 0.39672165 0.40709382]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "seq_len = 3\n",
        "embed_dim = 12\n",
        "num_heads = 3\n",
        "head_dim = embed_dim // num_heads"
      ],
      "metadata": {
        "id": "9LUB1quz7qhB"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(batch_size, seq_len, embed_dim).round(1)\n",
        "print(\"Input shape: \", x.shape, \"\\n\")\n",
        "print(\"Input:\\n\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz3YSeXMkAQe",
        "outputId": "341a4f74-e7a2-482a-b7ff-558b4e850c42"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:  (1, 3, 12) \n",
            "\n",
            "Input:\n",
            " [[[0.4 1.  0.7 0.6 0.2 0.2 0.1 0.9 0.6 0.7 0.  1. ]\n",
            "  [0.8 0.2 0.2 0.2 0.3 0.5 0.4 0.3 0.6 0.1 0.3 0.4]\n",
            "  [0.5 0.8 0.2 0.5 0.6 0.  0.6 0.2 0.1 0.9 1.  0.8]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The query weights for each head.\n",
        "wq0 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "wq1 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "wq2 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "\n",
        "# The key weights for each head. \n",
        "wk0 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "wk1 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "wk2 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "\n",
        "# The value weights for each head.\n",
        "wv0 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "wv1 = np.random.rand(embed_dim, head_dim).round(1)\n",
        "wv2 = np.random.rand(embed_dim, head_dim).round(1)"
      ],
      "metadata": {
        "id": "aAiaF8c2kAz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The three sets of query weights (one for each head):\")\n",
        "print(\"wq0:\\n\", wq0)\n",
        "print(\"wq1:\\n\", wq1)\n",
        "print(\"wq2:\\n\", wq1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNoJdAvmkEUX",
        "outputId": "b4737103-687d-48d5-afce-da6271800719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The three sets of query weights (one for each head):\n",
            "wq0:\n",
            " [[0.9 0.6 0.3 0.3]\n",
            " [0.7 0.9 0.9 0.8]\n",
            " [0.6 0.1 0.2 0.9]\n",
            " [0.6 0.  0.1 0.7]]\n",
            "wq1:\n",
            " [[0.  0.2 0.5 0.7]\n",
            " [0.7 0.2 0.7 0.2]\n",
            " [0.3 0.7 0.6 0.8]\n",
            " [0.7 0.6 0.1 0.4]]\n",
            "wq2:\n",
            " [[0.  0.2 0.5 0.7]\n",
            " [0.7 0.2 0.7 0.2]\n",
            " [0.3 0.7 0.6 0.8]\n",
            " [0.7 0.6 0.1 0.4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Geneated queries, keys, and values for the first head.\n",
        "q0 = np.dot(x, wq0)\n",
        "k0 = np.dot(x, wk0)\n",
        "v0 = np.dot(x, wv0)\n",
        "\n",
        "# Geneated queries, keys, and values for the second head.\n",
        "q1 = np.dot(x, wq1)\n",
        "k1 = np.dot(x, wk1)\n",
        "v1 = np.dot(x, wv1)\n",
        "\n",
        "# Geneated queries, keys, and values for the third head.\n",
        "q2 = np.dot(x, wq2)\n",
        "k2 = np.dot(x, wk2)\n",
        "v2 = np.dot(x, wv2)"
      ],
      "metadata": {
        "id": "_2A-4jKUkGaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q, K, and V for first head:\\n\")\n",
        "\n",
        "print(f\"q0 {q0.shape}:\\n\", q0, \"\\n\")\n",
        "print(f\"k0 {k0.shape}:\\n\", k0, \"\\n\")\n",
        "print(f\"v0 {v0.shape}:\\n\", v0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQYOlM3kkIsU",
        "outputId": "16744f63-82e0-4b27-d072-283a33f1ea71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q, K, and V for first head:\n",
            "\n",
            "q0 (1, 3, 4):\n",
            " [[[1.42 0.36 0.45 1.61]\n",
            "  [1.6  0.89 0.94 1.79]\n",
            "  [1.19 0.49 0.44 1.03]]] \n",
            "\n",
            "k0 (1, 3, 4):\n",
            " [[[1.98 1.47 0.76 1.12]\n",
            "  [1.61 1.83 0.91 1.5 ]\n",
            "  [1.36 1.04 0.74 0.98]]] \n",
            "\n",
            "v0 (1, 3, 4):\n",
            " [[[0.98 0.85 1.   0.68]\n",
            "  [1.35 0.92 0.85 0.79]\n",
            "  [0.48 0.85 0.53 0.65]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "  key_dim = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  scaled_scores = tf.matmul(query, key, transpose_b=True) / np.sqrt(key_dim)\n",
        "\n",
        "  if mask is not None:\n",
        "    scaled_scores = tf.where(mask==0, -np.inf, scaled_scores)\n",
        "\n",
        "  softmax = tf.keras.layers.Softmax()\n",
        "  weights = softmax(scaled_scores) \n",
        "  return tf.matmul(weights, value), weights"
      ],
      "metadata": {
        "id": "uEOedj2OqAdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out0, attn_weights0 = scaled_self_attention(q0, k0, v0)\n",
        "\n",
        "print(\"Output from first attention head: \", out0, \"\\n\")\n",
        "print(\"Attention weights from first head: \", attn_weights0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "SUPN8epUkK0V",
        "outputId": "294a6197-07a0-4897-9ccd-6bec84238496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-98ce7d93a6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_self_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output from first attention head: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attention weights from first head: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-dcee5b4c017e>\u001b[0m in \u001b[0;36mscaled_self_attention\u001b[0;34m(query, key, value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscaled_self_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mkey_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mQK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m#/np.sqrt(key_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (1,3,4) and (4,3,1) not aligned: 4 (dim 2) != 3 (dim 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "seq_len = 3\n",
        "embed_dim = 12\n",
        "num_heads = 3\n",
        "head_dim = embed_dim // num_heads"
      ],
      "metadata": {
        "id": "OZbSK_I-QD8o"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to overcome problems with numpy dot product for batch\n",
        "## create torch array\n",
        "\n",
        "x = torch.randn(batch_size, seq_len, embed_dim)\n",
        "\n",
        "print(\"Input shape: \", x.shape, \"\\n\")\n",
        "print(\"Input:\\n\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yuCrBgu1QwD",
        "outputId": "4d624241-45e0-49bf-e17b-3ee111bf6216"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:  torch.Size([1, 3, 12]) \n",
            "\n",
            "Input:\n",
            " tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
            "          -1.6047, -0.7521,  1.6487, -0.3925, -1.4036],\n",
            "         [-0.7279, -0.5594, -0.7688,  0.7624,  1.6423, -0.1596, -0.4974,\n",
            "           0.4396,  0.3189, -0.4245,  0.3057, -0.7746],\n",
            "         [ 0.0349,  0.3211,  1.5736, -0.8455, -1.2742,  2.1228, -1.2347,\n",
            "          -0.4879, -1.4181,  0.8963,  0.0499,  2.2667]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wq0 = torch.rand(embed_dim, head_dim)\n",
        "wq1 = torch.rand(embed_dim, head_dim)\n",
        "wq2 = torch.rand(embed_dim, head_dim)\n",
        "\n",
        "# The key weights for each head. \n",
        "wk0 = torch.rand(embed_dim, head_dim)\n",
        "wk1 = torch.rand(embed_dim, head_dim)\n",
        "wk2 = torch.rand(embed_dim, head_dim)\n",
        "\n",
        "# The value weights for each head.\n",
        "wv0 = torch.rand(embed_dim, head_dim)\n",
        "wv1 = torch.rand(embed_dim, head_dim)\n",
        "wv2 = torch.rand(embed_dim, head_dim)"
      ],
      "metadata": {
        "id": "N4pkyHch1wid"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wq0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4qdjpu_2bHQ",
        "outputId": "53eafe89-c0b0-4c55-a410-29f83693111d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(x,wq0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc5gtPbqF-Gu",
        "outputId": "42f3e1d8-edc8-423b-9331-6977a6a01895"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.0163e+00,  1.5319e+00,  5.1243e-01,  1.6608e+00],\n",
              "         [-5.1072e-01, -8.7488e-01,  5.7035e-01, -3.2563e-03],\n",
              "         [ 3.2986e+00, -7.5188e-02, -1.6818e+00, -1.2551e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.einsum('bij,jk->bik', x, wq0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFT-w36Z2L2w",
        "outputId": "01d31dd9-06cb-4e68-bb56-9a3ac7baed25"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.0163e+00,  1.5319e+00,  5.1243e-01,  1.6608e+00],\n",
              "         [-5.1072e-01, -8.7488e-01,  5.7035e-01, -3.2562e-03],\n",
              "         [ 3.2986e+00, -7.5188e-02, -1.6818e+00, -1.2551e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_function = nn.Softmax(dim=-1)\n",
        "input = torch.randn(1,3, 3,4)\n",
        "print(input)\n",
        "output = softmax_function(input)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMyJ-AwyNZC_",
        "outputId": "e44d7d86-67d3-4b6b-f09e-f3dd869ba48d"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 1.8595,  2.6221,  0.3691,  0.3803],\n",
            "          [ 0.1990, -0.2361,  0.3034, -0.4501],\n",
            "          [ 0.4739,  0.6503,  1.1662,  0.0169]],\n",
            "\n",
            "         [[ 0.5326, -0.6035, -0.1743,  0.6092],\n",
            "          [-0.8032, -1.1209,  0.1956, -0.7815],\n",
            "          [-0.9086,  0.3130,  0.8050, -1.1134]],\n",
            "\n",
            "         [[ 0.5258,  1.6828,  0.0967,  0.2571],\n",
            "          [ 0.6378,  0.1598,  1.7698,  0.6268],\n",
            "          [-0.4976, -0.1823, -0.2120,  0.8162]]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.2780, 0.5960, 0.0626, 0.0633],\n",
              "          [0.3049, 0.1973, 0.3385, 0.1593],\n",
              "          [0.2073, 0.2473, 0.4142, 0.1312]],\n",
              "\n",
              "         [[0.3456, 0.1109, 0.1704, 0.3731],\n",
              "          [0.1830, 0.1332, 0.4968, 0.1870],\n",
              "          [0.0930, 0.3154, 0.5159, 0.0758]],\n",
              "\n",
              "         [[0.1787, 0.5683, 0.1164, 0.1366],\n",
              "          [0.1751, 0.1086, 0.5431, 0.1732],\n",
              "          [0.1347, 0.1847, 0.1793, 0.5013]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_self_attention_torch(query, key, value):\n",
        "  key_dim = key.shape[-1]\n",
        "  QK = torch.div(torch.matmul(query,key.T),np.sqrt(key_dim))\n",
        "  print(\"---\")\n",
        "  print(QK.shape)\n",
        "  #sf = nn.Softmax( dim=1)\n",
        "  scaled_QK = softmax_function(QK)\n",
        "  print(scaled_QK.shape)\n",
        "  QKV = torch.matmul(scaled_QK, value)\n",
        "  print(QKV.shape)\n",
        "  return QKV, scaled_QK"
      ],
      "metadata": {
        "id": "y74xrI-wkPMc"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geneated queries, keys, and values for the first head.\n",
        "q0 = torch.matmul(x, wq0)\n",
        "k0 = torch.matmul(x, wk0)\n",
        "v0 = torch.matmul(x, wv0)\n",
        "\n",
        "# Geneated queries, keys, and values for the second head.\n",
        "q1 = torch.matmul(x, wq1)\n",
        "k1 = torch.matmul(x, wk1)\n",
        "v1 = torch.matmul(x, wv1)\n",
        "\n",
        "# Geneated queries, keys, and values for the third head.\n",
        "q2 = torch.matmul(x, wq2)\n",
        "k2 = torch.matmul(x, wk2)\n",
        "v2 = torch.matmul(x, wv2)"
      ],
      "metadata": {
        "id": "mCnyKS72PjiV"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q, K, and V for first head:\\n\")\n",
        "\n",
        "print(f\"q0 {q0.shape}:\\n\", q0, \"\\n\")\n",
        "print(f\"k0 {k0.shape}:\\n\", k0, \"\\n\")\n",
        "print(f\"v0 {v0.shape}:\\n\", v0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFIA897APt8q",
        "outputId": "dc563c88-49e4-4a74-8029-2a66ac4789ac"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q, K, and V for first head:\n",
            "\n",
            "q0 torch.Size([1, 3, 4]):\n",
            " tensor([[[-3.0163e+00,  1.5319e+00,  5.1243e-01,  1.6608e+00],\n",
            "         [-5.1072e-01, -8.7488e-01,  5.7035e-01, -3.2563e-03],\n",
            "         [ 3.2986e+00, -7.5188e-02, -1.6818e+00, -1.2551e+00]]]) \n",
            "\n",
            "k0 torch.Size([1, 3, 4]):\n",
            " tensor([[[ 0.0080, -0.4441, -0.3962,  0.0140],\n",
            "         [-1.2463, -0.5058, -0.2431,  1.1875],\n",
            "         [ 3.4878,  0.3210,  1.5877, -1.9066]]]) \n",
            "\n",
            "v0 torch.Size([1, 3, 4]):\n",
            " tensor([[[-0.8313, -1.2514,  2.0560, -2.1358],\n",
            "         [ 0.7614, -0.5448, -0.9581,  1.5510],\n",
            "         [-0.2805,  1.5310,  0.7963,  0.5893]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out0, attn_weights0 = scaled_self_attention_torch(q0, k0, v0)\n",
        "\n",
        "print(\"Output from first attention head: \", out0, \"\\n\")\n",
        "print(\"Attention weights from first head: \", attn_weights0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "j2Rpbk-RPO8S",
        "outputId": "00208bdf-7459-49bc-a19f-9cb6c6da4a04"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-331783bca393>:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
            "  QK = torch.div(torch.matmul(query,key.T),np.sqrt(key_dim))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-bfac84fc7cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_self_attention_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output from first attention head: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attention weights from first head: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-331783bca393>\u001b[0m in \u001b[0;36mscaled_self_attention_torch\u001b[0;34m(query, key, value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscaled_self_attention_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mkey_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mQK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [4, 4] but got: [4, 3]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYth47s_UceD",
        "outputId": "719292ca-1d61-42b4-dcc4-45f25b3afd69"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6788,  1.7449, -0.4234,  0.7830],\n",
              "         [-0.5399,  0.5887, -0.0268, -1.2599],\n",
              "         [ 2.4524,  2.3112,  1.5315,  0.1854]]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IezKm_IqUfE3",
        "outputId": "7477a633-5d1b-4792-a657-021b39164e97"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.4471,  0.4132,  1.3002,  1.5290],\n",
              "         [-0.7078,  1.5979, -1.0892, -0.1337],\n",
              "         [-1.7239,  0.2325,  0.2377,  0.6269]]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k0.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lqiodsYUhEE",
        "outputId": "c0690e82-8e52-47dc-a139-454ada7b4fda"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.4471],\n",
              "         [-0.7078],\n",
              "         [-1.7239]],\n",
              "\n",
              "        [[ 0.4132],\n",
              "         [ 1.5979],\n",
              "         [ 0.2325]],\n",
              "\n",
              "        [[ 1.3002],\n",
              "         [-1.0892],\n",
              "         [ 0.2377]],\n",
              "\n",
              "        [[ 1.5290],\n",
              "         [-0.1337],\n",
              "         [ 0.6269]]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.einsum('bij,bkj->bik', q0, k0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQbPr2OeSicv",
        "outputId": "772ba169-4acf-43c3-9ad0-cc05b72a18b3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.3498,  2.6644, -0.3742],\n",
              "         [-2.4992,  1.5205,  0.2715],\n",
              "         [ 6.7784,  0.2647, -3.2098]]])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Changing our self attention function\n",
        "\n",
        "def scaled_self_attention_torch(query, key, value):\n",
        "  key_dim = key.shape[-1]\n",
        "  QK = torch.div(torch.einsum('bij,bkj->bik',query,key),np.sqrt(key_dim))\n",
        "  print(\"---\")\n",
        "  print(QK.shape)\n",
        "  #sf = nn.Softmax( dim=1)\n",
        "  scaled_QK = softmax_function(QK)\n",
        "  print(scaled_QK.shape)\n",
        "  QKV = torch.matmul(scaled_QK, value)\n",
        "  print(QKV.shape)\n",
        "  return QKV, scaled_QK"
      ],
      "metadata": {
        "id": "5ebVqGk7SDC0"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out0, attn_weights0 = scaled_self_attention_torch(q0, k0, v0)\n",
        "\n",
        "print(\"Output from first attention head: \\n\", out0, \"\\n\")\n",
        "print(\"Attention weights from first head: \\n\", attn_weights0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m-EINxPUwZy",
        "outputId": "a8ec07cf-b2a4-4c2b-8488-994881e33f5c"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "torch.Size([1, 3, 3])\n",
            "torch.Size([1, 3, 3])\n",
            "torch.Size([1, 3, 4])\n",
            "Output from first attention head: \n",
            " tensor([[[ 0.6748, -0.5827, -0.7942,  1.3508],\n",
            "         [ 0.0488, -0.4205,  0.3526,  0.1533],\n",
            "         [-0.2831,  1.5158,  0.8024,  0.5754]]]) \n",
            "\n",
            "Attention weights from first head: \n",
            " tensor([[[5.4253e-02, 9.4557e-01, 1.7291e-04],\n",
            "         [3.3386e-01, 4.9262e-01, 1.7352e-01],\n",
            "         [5.2320e-03, 2.7894e-04, 9.9449e-01]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1, _ = scaled_self_attention_torch(q1, k1, v1)\n",
        "out2, _ = scaled_self_attention_torch(q1, k1, v1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw33IwAEUy5M",
        "outputId": "afa727fc-6f37-4f81-a505-684f9d7bfbbf"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "torch.Size([1, 3, 3])\n",
            "torch.Size([1, 3, 3])\n",
            "torch.Size([1, 3, 4])\n",
            "---\n",
            "torch.Size([1, 3, 3])\n",
            "torch.Size([1, 3, 3])\n",
            "torch.Size([1, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_out_a = torch.concatenate([out0,out1, out2], axis  = -1)"
      ],
      "metadata": {
        "id": "Y6CABU76VgvQ"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Combined output from all heads {combined_out_a.size()} :\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hrdBSLuVy4i",
        "outputId": "d0e0c4eb-12ab-41b0-a234-6a1bde0149e8"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined output from all heads torch.Size([1, 3, 12]) :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_out_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMyvF_sEV-gE",
        "outputId": "62344dcb-fe7e-4732-8769-b6498f970eca"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6748, -0.5827, -0.7942,  1.3508,  2.1227, -1.9256,  0.6278,\n",
              "          -2.3120,  2.1227, -1.9256,  0.6278, -2.3120],\n",
              "         [ 0.0488, -0.4205,  0.3526,  0.1533,  0.7703, -0.3158,  0.4023,\n",
              "          -0.9044,  0.7703, -0.3158,  0.4023, -0.9044],\n",
              "         [-0.2831,  1.5158,  0.8024,  0.5754, -0.9044, -0.6448, -0.8448,\n",
              "           0.0312, -0.9044, -0.6448, -0.8448,  0.0312]]])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## just single weight matrix"
      ],
      "metadata": {
        "id": "yrgxiQw-WDKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wq = torch.concatenate([wq0,wq1,wq2], axis = -1)"
      ],
      "metadata": {
        "id": "vtd159QnWNVA"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wk = torch.concatenate([wk0,wk1,wk2], axis = -1)\n",
        "wv = torch.concatenate([wv0,wv1,wv2], axis = -1)"
      ],
      "metadata": {
        "id": "QWqhnBgfWW1x"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wq.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7giqyVzsWmOh",
        "outputId": "5df95206-6325-40d3-bf37-d2cf1981b55e"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_s = torch.matmul(x, wq)\n",
        "k_s = torch.matmul(x, wk)\n",
        "v_s = torch.matmul(x, wv)\n"
      ],
      "metadata": {
        "id": "4na75F3MWq8q"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_s.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLPCzaBqW8kr",
        "outputId": "a39c776d-16a0-42b7-f995-dfbcb069fd1e"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqkXR9YGW-Le",
        "outputId": "3eb012db-a41e-4e74-a716-4d3c4ab319da"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.0163e+00,  1.5319e+00,  5.1243e-01,  1.6608e+00, -2.6275e+00,\n",
              "          -9.8147e-01, -1.0185e+00, -1.5966e+00,  1.7143e-01, -2.2158e+00,\n",
              "           3.7624e-01,  5.6532e-01],\n",
              "         [-5.1072e-01, -8.7488e-01,  5.7035e-01, -3.2563e-03,  1.0849e+00,\n",
              "          -7.0866e-01, -8.3605e-01, -6.1532e-01, -7.1942e-01, -5.7810e-02,\n",
              "          -7.0680e-01,  6.2113e-01],\n",
              "         [ 3.2986e+00, -7.5188e-02, -1.6818e+00, -1.2551e+00,  3.4234e-01,\n",
              "           6.4476e-01,  3.0574e+00,  2.3347e+00,  1.6309e+00,  1.4771e+00,\n",
              "           1.1949e+00,  5.8007e-01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_s_reshaped = torch.reshape(q_s, [batch_size, seq_len, num_heads, head_dim])\n",
        "q_s_reshaped.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMm8190hXED-",
        "outputId": "3069baf0-dbe5-4605-bfd3-e01872bbdc57"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_s_reshaped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an24ellVYImr",
        "outputId": "af353b14-655e-44ff-804d-458d8be5ee16"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-3.0163e+00,  1.5319e+00,  5.1243e-01,  1.6608e+00],\n",
              "          [-2.6275e+00, -9.8147e-01, -1.0185e+00, -1.5966e+00],\n",
              "          [ 1.7143e-01, -2.2158e+00,  3.7624e-01,  5.6532e-01]],\n",
              "\n",
              "         [[-5.1072e-01, -8.7488e-01,  5.7035e-01, -3.2563e-03],\n",
              "          [ 1.0849e+00, -7.0866e-01, -8.3605e-01, -6.1532e-01],\n",
              "          [-7.1942e-01, -5.7810e-02, -7.0680e-01,  6.2113e-01]],\n",
              "\n",
              "         [[ 3.2986e+00, -7.5188e-02, -1.6818e+00, -1.2551e+00],\n",
              "          [ 3.4234e-01,  6.4476e-01,  3.0574e+00,  2.3347e+00],\n",
              "          [ 1.6309e+00,  1.4771e+00,  1.1949e+00,  5.8007e-01]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_s_transposed = torch.transpose(q_s_reshaped,1,2)\n",
        "q_s_transposed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtiZmgp-YLUx",
        "outputId": "12dbf659-1ccf-400a-8e55-672d026a284d"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-3.0163e+00,  1.5319e+00,  5.1243e-01,  1.6608e+00],\n",
              "          [-5.1072e-01, -8.7488e-01,  5.7035e-01, -3.2563e-03],\n",
              "          [ 3.2986e+00, -7.5188e-02, -1.6818e+00, -1.2551e+00]],\n",
              "\n",
              "         [[-2.6275e+00, -9.8147e-01, -1.0185e+00, -1.5966e+00],\n",
              "          [ 1.0849e+00, -7.0866e-01, -8.3605e-01, -6.1532e-01],\n",
              "          [ 3.4234e-01,  6.4476e-01,  3.0574e+00,  2.3347e+00]],\n",
              "\n",
              "         [[ 1.7143e-01, -2.2158e+00,  3.7624e-01,  5.6532e-01],\n",
              "          [-7.1942e-01, -5.7810e-02, -7.0680e-01,  6.2113e-01],\n",
              "          [ 1.6309e+00,  1.4771e+00,  1.1949e+00,  5.8007e-01]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_s_transposed =torch.transpose(torch.reshape(k_s, [batch_size, seq_len, num_heads, head_dim]),1,2)\n",
        "v_s_transposed =torch.transpose(torch.reshape(v_s, [batch_size, seq_len, num_heads, head_dim]),1,2)\n"
      ],
      "metadata": {
        "id": "8opTRxdbY5Ol"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_s_transposed.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kayuu1daaHkK",
        "outputId": "359ccdb5-8b42-4ae3-94d6-70f398be56fa"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make a single call to self attention\n",
        "\n",
        "out, attn_weights = scaled_self_attention_torch(q_s_transposed, k_s_transposed, v_s_transposed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "oTwNm67rZgWW",
        "outputId": "c764861c-10d0-4ee3-dfa0-e36d088dcae0"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-86eadcaa41d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## make a single call to self attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_self_attention_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_s_transposed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_s_transposed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_s_transposed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-20a3aa7e8901>\u001b[0m in \u001b[0;36mscaled_self_attention_torch\u001b[0;34m(query, key, value)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscaled_self_attention_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mkey_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mQK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bij,bkj->bik'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (4) for operand 0 and no ellipsis was given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make the necessary changes to the function\n",
        "print(q_s_transposed.size(), \" - \",  torch.transpose(k_s_transposed,-1,-2).size())\n",
        "torch.matmul(q_s_transposed, torch.transpose(k_s_transposed,-1,-2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sctb9N2ZyBi",
        "outputId": "decc7f63-a472-40be-9145-0c9ff40df4d8"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 3, 4])  -  torch.Size([1, 3, 4, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 2.3498,  2.6644, -0.3742],\n",
              "          [-2.4992,  1.5205,  0.2715],\n",
              "          [ 6.7784,  0.2647, -3.2098]],\n",
              "\n",
              "         [[ 9.2551,  1.0072,  2.7328],\n",
              "          [ 4.6929, -0.0826,  2.2253],\n",
              "          [ 9.0149,  3.6956,  4.9875]],\n",
              "\n",
              "         [[11.9529,  3.0278, 13.9837],\n",
              "          [-0.2167, -0.2847,  0.3090],\n",
              "          [ 7.2083,  1.6485,  8.4704]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.einsum('bsij,bskj->bsik',q_s_transposed,k_s_transposed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1B7M6F5cErb",
        "outputId": "3f22ef49-1379-432b-8871-e0e08f26159f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 2.3498,  2.6644, -0.3742],\n",
              "          [-2.4992,  1.5205,  0.2715],\n",
              "          [ 6.7784,  0.2647, -3.2098]],\n",
              "\n",
              "         [[ 9.2551,  1.0072,  2.7328],\n",
              "          [ 4.6929, -0.0826,  2.2253],\n",
              "          [ 9.0149,  3.6956,  4.9875]],\n",
              "\n",
              "         [[11.9529,  3.0278, 13.9837],\n",
              "          [-0.2167, -0.2847,  0.3090],\n",
              "          [ 7.2083,  1.6485,  8.4704]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_s_transposed.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omPlXwdpcUea",
        "outputId": "1488756d-f418-46ac-8120-7ea8a554ba15"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Changing our self attention function\n",
        "\n",
        "def scaled_self_attention_torch(query, key, value):\n",
        "  key_dim = key.shape[-1]\n",
        "  key_reshape = torch.transpose(key,-1,-2)\n",
        "  #QK = torch.div(torch.einsum('bsij,bskj->bsik',query,key),np.sqrt(key_dim))\n",
        "  QK = torch.div(torch.matmul(query,key_reshape),np.sqrt(key_dim))\n",
        "  print(\"---\")\n",
        "  print(QK.shape)\n",
        "  #sf = nn.Softmax( dim=1)\n",
        "  scaled_QK = softmax_function(QK)\n",
        "  print(scaled_QK.shape)\n",
        "  QKV = torch.matmul(scaled_QK, value)\n",
        "  print(QKV.shape)\n",
        "  return QKV, scaled_QK"
      ],
      "metadata": {
        "id": "fphi6Zd0Z8CY"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out, attn_weights = scaled_self_attention_torch(q_s_transposed, k_s_transposed, v_s_transposed)\n",
        "out.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDMvY-BHamWC",
        "outputId": "7f08a78b-7bd7-457b-fae6-aa96a0e39622"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "torch.Size([1, 3, 3, 3])\n",
            "torch.Size([1, 3, 3, 3])\n",
            "torch.Size([1, 3, 3, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0fZl_RdapRO",
        "outputId": "e4468e81-2640-4bf7-e8b3-a5fb605261e2"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.6748, -0.5827, -0.7942,  1.3508],\n",
              "          [ 0.0488, -0.4205,  0.3526,  0.1533],\n",
              "          [-0.2831,  1.5158,  0.8024,  0.5754]],\n",
              "\n",
              "         [[ 2.1227, -1.9256,  0.6278, -2.3120],\n",
              "          [ 0.7703, -0.3158,  0.4023, -0.9044],\n",
              "          [-0.9044, -0.6448, -0.8448,  0.0312]],\n",
              "\n",
              "         [[-1.6386,  0.4759, -0.4717,  2.2239],\n",
              "          [-0.4508,  0.1738, -0.2344,  0.8132],\n",
              "          [ 1.4882,  0.6556, -0.9764,  1.6874]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtXyMzdaar7K",
        "outputId": "9b30e503-1581-451b-ba33-f5b34bb1d691"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[5.4253e-02, 9.4557e-01, 1.7291e-04],\n",
              "          [3.3386e-01, 4.9262e-01, 1.7352e-01],\n",
              "          [5.2320e-03, 2.7894e-04, 9.9449e-01]],\n",
              "\n",
              "         [[9.9958e-01, 3.8871e-04, 3.6176e-05],\n",
              "          [4.9419e-01, 1.6953e-01, 3.3627e-01],\n",
              "          [1.5876e-04, 8.6969e-01, 1.3015e-01]],\n",
              "\n",
              "         [[8.6893e-01, 9.9629e-02, 3.1445e-02],\n",
              "          [2.7580e-01, 4.5759e-01, 2.6661e-01],\n",
              "          [9.2030e-03, 9.4160e-02, 8.9664e-01]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzjrcACya4xT",
        "outputId": "10d7bab1-5578-4483-8a06-dd7d40029226"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6748, -0.5827, -0.7942,  1.3508],\n",
              "         [ 0.0488, -0.4205,  0.3526,  0.1533],\n",
              "         [-0.2831,  1.5158,  0.8024,  0.5754]]])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_out_b = torch.reshape(torch.transpose(out,1,2), shape=[batch_size, seq_len, embed_dim])"
      ],
      "metadata": {
        "id": "82gu6F-dbOwn"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_out_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnIepTj2hPVE",
        "outputId": "c4802086-61d0-4419-bde4-66c08d17a57a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6748, -0.5827, -0.7942,  1.3508,  2.1227, -1.9256,  0.6278,\n",
              "          -2.3120, -1.6386,  0.4759, -0.4717,  2.2239],\n",
              "         [ 0.0488, -0.4205,  0.3526,  0.1533,  0.7703, -0.3158,  0.4023,\n",
              "          -0.9044, -0.4508,  0.1738, -0.2344,  0.8132],\n",
              "         [-0.2831,  1.5158,  0.8024,  0.5754, -0.9044, -0.6448, -0.8448,\n",
              "           0.0312,  1.4882,  0.6556, -0.9764,  1.6874]]])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_out_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaxgLnVAhRvG",
        "outputId": "1c2aa195-85d9-4f4a-8862-0b89474b6b41"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6748, -0.5827, -0.7942,  1.3508,  2.1227, -1.9256,  0.6278,\n",
              "          -2.3120,  2.1227, -1.9256,  0.6278, -2.3120],\n",
              "         [ 0.0488, -0.4205,  0.3526,  0.1533,  0.7703, -0.3158,  0.4023,\n",
              "          -0.9044,  0.7703, -0.3158,  0.4023, -0.9044],\n",
              "         [-0.2831,  1.5158,  0.8024,  0.5754, -0.9044, -0.6448, -0.8448,\n",
              "           0.0312, -0.9044, -0.6448, -0.8448,  0.0312]]])"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7LLPtyZhaOG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}